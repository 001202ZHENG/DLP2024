{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "4jVkOWmgFT1p"
      },
      "source": [
        "# **Practical session on Transfer Learning**\n",
        "This Pratical session proposes to study several techniques for improving challenging context, in which few data and resources are available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "QLKnIngy_2hg"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "**Context :**\n",
        "\n",
        "Assume we are in a context where few \"gold\" labeled data are available for training, say\n",
        "\n",
        "$$\\mathcal{X}_{\\text{train}} = \\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$$\n",
        "\n",
        "where $N_{\\text{train}}$ is small.\n",
        "\n",
        "A large test set $\\mathcal{X}_{\\text{test}}$ as well as a large amount of unlabeled data, $\\mathcal{X}$, is available. We also assume that we have a limited computational budget (e.g., no GPUs).\n",
        "\n",
        "**Instructions to follow :**\n",
        "\n",
        "For each question, write a commented *Code* or a complete answer as a *Markdown*. When the objective of a question is to report a CNN accuracy, please use the following format to report it, at the end of the question :\n",
        "\n",
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   XXX  | XXX | XXX | XXX |\n",
        "\n",
        "If applicable, please add the field corresponding to the  __Accuracy on Full Data__ as well as a link to the __Reference paper__ you used to report those numbers. (You do not need to train a CNN on the full CIFAR10 dataset!)\n",
        "\n",
        "In your final report, please *keep the logs of each training procedure* you used. We will only run this jupyter if we have some doubts on your implementation.\n",
        "\n",
        "The total file sizes should be reasonable (feasible with 2MB only!). You will be asked to hand in the notebook, together with any necessary files required to run it if any.\n",
        "\n",
        "You can use https://colab.research.google.com/ to run your experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "YmTCQPSh_2hg"
      },
      "source": [
        "## Training set creation\n",
        "__Question 1 (1 points) :__ Propose a dataloader to obtain a training loader that will only use the first 100 samples of the CIFAR-10 training set.\n",
        "\n",
        "Additional information :  \n",
        "\n",
        "*   CIFAR10 dataset : https://en.wikipedia.org/wiki/CIFAR-10\n",
        "*   You can directly use the dataloader framework from Pytorch.\n",
        "*   Alternatively you can modify the file : https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "uZkC5IxR_2hh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMCxsoz4td4O",
        "outputId": "d297868e-eec1-4d63-e21d-48923bb13050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47874294.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# Only use the first 100 samples\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_set.data = train_set.data[:100]\n",
        "train_set.targets = train_set.targets[:100]\n",
        "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# For validation during train loop\n",
        "unlabel_set =  torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "unlabel_set.data = unlabel_set.data[100:]\n",
        "unlabel_set.targets = unlabel_set.targets[100:]\n",
        "unlabel_dataloader = torch.utils.data.DataLoader(unlabel_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Test set\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "fUno1nmu_2hh"
      },
      "source": [
        "* This is our dataset $\\mathcal{X}_{\\text{train}}$, it will be used until the end of this project.\n",
        "\n",
        "* The remaining samples correspond to $\\mathcal{X}$.\n",
        "\n",
        "* The testing set $\\mathcal{X}_{\\text{test}}$ corresponds to the whole testing set of CIFAR-10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "Vr0d4o5L_2hi"
      },
      "source": [
        "## Testing procedure\n",
        "__Question 2 (0.5 points):__ Explain why the evaluation of the training procedure is difficult. Propose several solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "ppiTrnpd_2hi"
      },
      "source": [
        "The evaluation of the training procedure is difficult because sometimes the accuracy rate is very high on traning set but it is overfitting, and may have a poor performance on the testing set. This is a very commen dilemma when trying to balance between accuracy and generalization. Especially when training on a small dataset, it is very easy to overfit to the training data.\n",
        "\n",
        "\n",
        "**Solutions**\n",
        "\n",
        "* Data Augmentation: We can use different data augmentation techniques to artificially increase the size of the dataset. This can help reduce overfitting and improve the generalization of the model.\n",
        "* Regularization: We can implement regularization techniques such as dropout or weight decay to penalize large weights and reduce the risk of overfitting.\n",
        "* Early Stopping: We can monitor the validation loss during training and stop the training process if the validation loss does not improve for a certain number of epochs. This can also help reduce overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "OEaIwILB_2hi"
      },
      "source": [
        "# The Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "M-PQZ2Vl_2hi"
      },
      "source": [
        "In this section, the goal is to train a CNN on $\\mathcal{X}_{\\text{train}}$ and compare its performance with reported numbers from the litterature. You will have to re-use and/or design a standard classification pipeline. You should optimize your pipeline to obtain the best performances (image size, data augmentation by flip, ...).\n",
        "\n",
        "The key ingredients for training a CNN are the batch size, as well as the learning rate scheduler (i.e. how to decrease the learning rate as a function of the number of epochs). A possible scheduler is to start the learning rate at 0.1 and decreasing it every 30 epochs by 10. In case of divergence, reduce the learning rate. A potential batch size could be 10, yet this can be cross-validated.\n",
        "\n",
        "You can get some baselines accuracies in this paper (obviously, it is a different context for those researchers who had access to GPUs!) : http://openaccess.thecvf.com/content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "ARHWPXrY_2hi"
      },
      "source": [
        "## ResNet architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "voMbGoNw_2hj"
      },
      "source": [
        "__Question 3 (2 points) :__ Write a classification pipeline for $\\mathcal{X}_{\\text{train}}$, train from scratch and evaluate a *ResNet-18* architecture specific to CIFAR10 (details about the ImageNet model can be found here: https://arxiv.org/abs/1512.03385). Please report the accuracy obtained on the whole dataset as well as the reference paper/GitHub link.\n",
        "\n",
        "*Hint :* You can re-use the following code : https://github.com/kuangliu/pytorch-cifar. During a training of 10 epochs, a batch size of 10 and a learning rate of 0.01, one obtains 40% accuracy on $\\mathcal{X}_{\\text{train}}$ (\\~2 minutes) and 20% accuracy on $\\mathcal{X}_{\\text{test}}$ (\\~5 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JSItiUNbtd4P"
      },
      "outputs": [],
      "source": [
        "#########################################\n",
        "### Training Pipeline\n",
        "#########################################\n",
        "\n",
        "def train(model, epochs, trainloader, valloader, optimizer, scheduler, criterion, device):\n",
        "    best_acc = 0.0\n",
        "    stop_time = 0\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "            # Assuming No GPUs\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            model.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # Update learning rate with scheduler\n",
        "        scheduler.step()\n",
        "        # Print out infomation\n",
        "        print('Epoch %d Train Loss: %.3f | Train Acc: %.3f%%' % (epoch + 1, train_loss / len(trainloader), 100.*correct/total))\n",
        "\n",
        "        # Validation\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(valloader):\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "                acc = 100.*correct/total\n",
        "\n",
        "        print('Epoch %d Validation Acc: %.3f%%' % (epoch + 1, acc))\n",
        "\n",
        "\n",
        "        # Early Stop\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), 'best_weights.pth')\n",
        "            stop_time = 0\n",
        "        else:\n",
        "            stop_time += 1\n",
        "            patience = 5\n",
        "            if (stop_time >= patience):\n",
        "              print('Validation accuracy no longer improves for %d epochs, early stopping.' % patience)\n",
        "              break\n",
        "\n",
        "    model.load_state_dict(torch.load('best_weights.pth'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "RVHhKmWN_2hj"
      },
      "outputs": [],
      "source": [
        "#########################################\n",
        "### ResNet-18, architecture from https://github.com/kuangliu/pytorch-cifar\n",
        "#########################################\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tZ04Jl9-td4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4efe42-fb8d-4cfb-840b-f378c3d84641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "model = ResNet18()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0sqJYzntd4Q",
        "outputId": "6fa77bfe-b3d6-4b5f-9e15-a00e0b65af5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 2.291 | Train Acc: 18.000%\n",
            "Epoch 1 Validation Acc: 9.994%\n",
            "Epoch 2 Train Loss: 1.957 | Train Acc: 34.000%\n",
            "Epoch 2 Validation Acc: 10.597%\n",
            "Epoch 3 Train Loss: 1.634 | Train Acc: 51.000%\n",
            "Epoch 3 Validation Acc: 10.142%\n",
            "Epoch 4 Train Loss: 1.278 | Train Acc: 63.000%\n",
            "Epoch 4 Validation Acc: 10.852%\n",
            "Epoch 5 Train Loss: 0.898 | Train Acc: 84.000%\n",
            "Epoch 5 Validation Acc: 20.567%\n",
            "Epoch 6 Train Loss: 0.534 | Train Acc: 98.000%\n",
            "Epoch 6 Validation Acc: 21.174%\n",
            "Epoch 7 Train Loss: 0.362 | Train Acc: 98.000%\n",
            "Epoch 7 Validation Acc: 21.487%\n",
            "Epoch 8 Train Loss: 0.259 | Train Acc: 99.000%\n",
            "Epoch 8 Validation Acc: 21.882%\n",
            "Epoch 9 Train Loss: 0.096 | Train Acc: 100.000%\n",
            "Epoch 9 Validation Acc: 22.369%\n",
            "Epoch 10 Train Loss: 0.068 | Train Acc: 100.000%\n",
            "Epoch 10 Validation Acc: 22.457%\n",
            "Epoch 11 Train Loss: 0.087 | Train Acc: 100.000%\n",
            "Epoch 11 Validation Acc: 22.523%\n",
            "Epoch 12 Train Loss: 0.041 | Train Acc: 100.000%\n",
            "Epoch 12 Validation Acc: 22.900%\n",
            "Epoch 13 Train Loss: 0.047 | Train Acc: 100.000%\n",
            "Epoch 13 Validation Acc: 23.132%\n",
            "Epoch 14 Train Loss: 0.037 | Train Acc: 100.000%\n",
            "Epoch 14 Validation Acc: 23.355%\n",
            "Epoch 15 Train Loss: 0.064 | Train Acc: 100.000%\n",
            "Epoch 15 Validation Acc: 23.104%\n",
            "Epoch 16 Train Loss: 0.036 | Train Acc: 100.000%\n",
            "Epoch 16 Validation Acc: 21.539%\n",
            "Epoch 17 Train Loss: 0.034 | Train Acc: 100.000%\n",
            "Epoch 17 Validation Acc: 22.140%\n",
            "Epoch 18 Train Loss: 0.054 | Train Acc: 98.000%\n",
            "Epoch 18 Validation Acc: 22.593%\n",
            "Epoch 19 Train Loss: 0.033 | Train Acc: 100.000%\n",
            "Epoch 19 Validation Acc: 22.040%\n",
            "Validation accuracy no longer improves for 5 epochs, early stopping.\n"
          ]
        }
      ],
      "source": [
        "best_model = train(model, 100, train_dataloader, unlabel_dataloader, optimizer, scheduler, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_v_Oy-OxnVd",
        "outputId": "4b3b6779-ebb0-494b-ab5c-94bb348de9d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 23 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = outputs.max(1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Test Acc: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5FTuaQMyH_s"
      },
      "source": [
        "\n",
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   ResNet18  | 18 | 100% | 24% |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "-C3mHqCk_2hj"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "8Tn9pW14_2hj"
      },
      "source": [
        "We propose to use pre-trained models on a classification and generative task, in order to improve the results of our setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "z8g_3ZDi_2hj"
      },
      "source": [
        "## ImageNet features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "PfYEhdFb_2hj"
      },
      "source": [
        "Now, we will use some pre-trained models on ImageNet and see how well they compare on CIFAR. A list is available on : https://pytorch.org/vision/stable/models.html.\n",
        "\n",
        "__Question 4 (1 points):__ Pick a model from the list above, adapt it for CIFAR10 and retrain its final layer (or a block of layers, depending on the resources to which you have access to). Report its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "collapsed": true,
        "id": "i_lh4xje_2hk"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "# Pre-trained resnet18 model\n",
        "# New weights with accuracy 89.078%\n",
        "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Reset the last layer\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpBzljjb0N9s"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4IIAQDD0URD",
        "outputId": "ed9a7520-56f1-493f-d584-8f2f0dc88a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Train Loss: 2.570 | Train Acc: 12.000%\n",
            "Epoch 1 Validation Acc: 13.437%\n",
            "Epoch 2 Train Loss: 1.600 | Train Acc: 51.000%\n",
            "Epoch 2 Validation Acc: 18.038%\n",
            "Epoch 3 Train Loss: 1.262 | Train Acc: 55.000%\n",
            "Epoch 3 Validation Acc: 22.032%\n",
            "Epoch 4 Train Loss: 0.883 | Train Acc: 70.000%\n",
            "Epoch 4 Validation Acc: 23.118%\n",
            "Epoch 5 Train Loss: 0.639 | Train Acc: 82.000%\n",
            "Epoch 5 Validation Acc: 24.487%\n",
            "Epoch 6 Train Loss: 0.514 | Train Acc: 86.000%\n",
            "Epoch 6 Validation Acc: 24.575%\n",
            "Epoch 7 Train Loss: 0.369 | Train Acc: 89.000%\n",
            "Epoch 7 Validation Acc: 25.242%\n",
            "Epoch 8 Train Loss: 0.401 | Train Acc: 88.000%\n",
            "Epoch 8 Validation Acc: 25.772%\n",
            "Epoch 9 Train Loss: 0.367 | Train Acc: 87.000%\n",
            "Epoch 9 Validation Acc: 26.545%\n",
            "Epoch 10 Train Loss: 0.310 | Train Acc: 86.000%\n",
            "Epoch 10 Validation Acc: 26.547%\n",
            "Epoch 11 Train Loss: 0.263 | Train Acc: 89.000%\n",
            "Epoch 11 Validation Acc: 28.246%\n",
            "Epoch 12 Train Loss: 0.281 | Train Acc: 93.000%\n",
            "Epoch 12 Validation Acc: 28.413%\n",
            "Epoch 13 Train Loss: 0.172 | Train Acc: 94.000%\n",
            "Epoch 13 Validation Acc: 28.281%\n",
            "Epoch 14 Train Loss: 0.206 | Train Acc: 90.000%\n",
            "Epoch 14 Validation Acc: 28.892%\n",
            "Epoch 15 Train Loss: 0.225 | Train Acc: 93.000%\n",
            "Epoch 15 Validation Acc: 29.607%\n",
            "Epoch 16 Train Loss: 0.192 | Train Acc: 93.000%\n",
            "Epoch 16 Validation Acc: 29.790%\n",
            "Epoch 17 Train Loss: 0.121 | Train Acc: 96.000%\n",
            "Epoch 17 Validation Acc: 30.234%\n",
            "Epoch 18 Train Loss: 0.099 | Train Acc: 98.000%\n",
            "Epoch 18 Validation Acc: 29.186%\n",
            "Epoch 19 Train Loss: 0.109 | Train Acc: 95.000%\n",
            "Epoch 19 Validation Acc: 28.731%\n",
            "Epoch 20 Train Loss: 0.175 | Train Acc: 94.000%\n",
            "Epoch 20 Validation Acc: 29.068%\n",
            "Epoch 21 Train Loss: 0.098 | Train Acc: 98.000%\n",
            "Epoch 21 Validation Acc: 29.415%\n",
            "Epoch 22 Train Loss: 0.147 | Train Acc: 97.000%\n",
            "Epoch 22 Validation Acc: 29.749%\n",
            "Validation accuracy no longer improves for 5 epochs, early stopping.\n"
          ]
        }
      ],
      "source": [
        "best_model = train(model, 100, train_dataloader, unlabel_dataloader, optimizer, scheduler, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNF4SLB_3yJi",
        "outputId": "9d667cb9-3799-4691-a0a0-949ecfed8cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Acc: 29 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = outputs.max(1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Test Acc: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLXgZkRA7N27"
      },
      "source": [
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   ResNet18  | 17 | 96% | 29% |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "SvkuMzLs_2hk"
      },
      "source": [
        "# Incorporating *a priori*\n",
        "Geometrical *a priori* are appealing for image classification tasks, though one might have to handle several boundary effects.\n",
        "\n",
        "__Question 5 (0.5 points) :__ Explain the issues when dealing with translations, rotations, scaling effects, color changes on $32\\times32$ images. Propose several ideas to tackle them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "TIaY60o1_2hk"
      },
      "source": [
        "When we mess around with 32*32 images by shifting them, rotating them, scaling them, or changing their colors, we end up losing some details. And since these small images don't have much detail to begin with, these changes can make them too distorted. This means the features that the model needs to learn from might not be clear anymore.\n",
        "\n",
        "To avoid this, we could stick to making only small adjustments like tiny shifts or rotations. This way, most of the important stuff in the image stays intact. Another option is to make the images bigger using special methods that fill in the gaps caused by resizing, which can help preserve more of the original information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "ds6e6teG_2hk"
      },
      "source": [
        "## Data augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "-Ek5wlOo_2hk"
      },
      "source": [
        "__Question 6 (4 points):__ Propose a set of geometric transformation beyond translation, and incorporate them in your training pipeline. Train the model of the __Question 3__ with them and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FqCjrXGk_2hk",
        "outputId": "29258944-bd59-4417-ff9d-d230ffaba1f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#########################################\n",
        "### Geometric transformation\n",
        "### Reference: https://github.com/kuangliu/pytorch-cifar\n",
        "#########################################\n",
        "\n",
        "original_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# X_train(100 samples from cifar10) union geometric_transformation(X_train)\n",
        "\n",
        "origin_train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=original_transform)\n",
        "origin_train_set.data = train_set.data[:100]\n",
        "origin_train_set.targets = train_set.targets[:100]\n",
        "\n",
        "transformed_train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "transformed_train_set.data = train_set.data[:100]\n",
        "transformed_train_set.targets = train_set.targets[:100]\n",
        "\n",
        "combined_train_set = torch.utils.data.ConcatDataset([origin_train_set, transformed_train_set])\n",
        "train_dataloader = torch.utils.data.DataLoader(combined_train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# For validation during train loop\n",
        "unlabel_set =  torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "unlabel_set.data = unlabel_set.data[100:]\n",
        "unlabel_set.targets = unlabel_set.targets[100:]\n",
        "unlabel_dataloader = torch.utils.data.DataLoader(unlabel_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Test set\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of batches in the train_dataloader:\", len(train_dataloader))\n",
        "print(\"Batch size:\", train_dataloader.batch_size)\n",
        "print(\"Number of samples in the train_dataloader:\", len(train_dataloader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0BIQor8hqnX",
        "outputId": "ec24cfbe-bd47-41f7-d464-560ce80ad451"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in the train_dataloader: 20\n",
            "Batch size: 10\n",
            "Number of samples in the train_dataloader: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKbmjP2_9zw9",
        "outputId": "c7d0afc2-b3c1-407e-b0d5-c5aee9f2bedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = ResNet18()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYABKaiN-vVq",
        "outputId": "1d41d3d6-f8be-4cf8-a26c-13ec3cf60f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 2.393 | Train Acc: 12.000%\n",
            "Epoch 1 Validation Acc: 9.994%\n",
            "Epoch 2 Train Loss: 2.355 | Train Acc: 15.500%\n",
            "Epoch 2 Validation Acc: 9.988%\n",
            "Epoch 3 Train Loss: 2.177 | Train Acc: 19.000%\n",
            "Epoch 3 Validation Acc: 15.912%\n",
            "Epoch 4 Train Loss: 2.017 | Train Acc: 27.500%\n",
            "Epoch 4 Validation Acc: 15.697%\n",
            "Epoch 5 Train Loss: 1.873 | Train Acc: 35.500%\n",
            "Epoch 5 Validation Acc: 20.627%\n",
            "Epoch 6 Train Loss: 1.722 | Train Acc: 39.000%\n",
            "Epoch 6 Validation Acc: 20.926%\n",
            "Epoch 7 Train Loss: 1.575 | Train Acc: 45.500%\n",
            "Epoch 7 Validation Acc: 18.361%\n",
            "Epoch 8 Train Loss: 1.463 | Train Acc: 45.500%\n",
            "Epoch 8 Validation Acc: 17.505%\n",
            "Epoch 9 Train Loss: 1.388 | Train Acc: 52.500%\n",
            "Epoch 9 Validation Acc: 22.283%\n",
            "Epoch 10 Train Loss: 1.211 | Train Acc: 56.500%\n",
            "Epoch 10 Validation Acc: 20.637%\n",
            "Epoch 11 Train Loss: 1.038 | Train Acc: 66.500%\n",
            "Epoch 11 Validation Acc: 22.481%\n",
            "Epoch 12 Train Loss: 0.871 | Train Acc: 71.000%\n",
            "Epoch 12 Validation Acc: 23.944%\n",
            "Epoch 13 Train Loss: 0.832 | Train Acc: 71.500%\n",
            "Epoch 13 Validation Acc: 21.389%\n",
            "Epoch 14 Train Loss: 0.743 | Train Acc: 78.500%\n",
            "Epoch 14 Validation Acc: 21.737%\n",
            "Epoch 15 Train Loss: 0.694 | Train Acc: 76.000%\n",
            "Epoch 15 Validation Acc: 24.194%\n",
            "Epoch 16 Train Loss: 0.764 | Train Acc: 75.000%\n",
            "Epoch 16 Validation Acc: 22.792%\n",
            "Epoch 17 Train Loss: 0.619 | Train Acc: 80.500%\n",
            "Epoch 17 Validation Acc: 23.251%\n",
            "Epoch 18 Train Loss: 0.481 | Train Acc: 86.000%\n",
            "Epoch 18 Validation Acc: 25.747%\n",
            "Epoch 19 Train Loss: 0.447 | Train Acc: 87.000%\n",
            "Epoch 19 Validation Acc: 21.447%\n",
            "Epoch 20 Train Loss: 0.455 | Train Acc: 85.500%\n",
            "Epoch 20 Validation Acc: 21.711%\n",
            "Epoch 21 Train Loss: 0.494 | Train Acc: 85.500%\n",
            "Epoch 21 Validation Acc: 24.892%\n",
            "Epoch 22 Train Loss: 0.546 | Train Acc: 83.000%\n",
            "Epoch 22 Validation Acc: 21.220%\n",
            "Epoch 23 Train Loss: 0.492 | Train Acc: 87.000%\n",
            "Epoch 23 Validation Acc: 22.461%\n",
            "Validation accuracy no longer improves for 5 epochs, early stopping.\n"
          ]
        }
      ],
      "source": [
        "best_model = train(model, 100, train_dataloader, unlabel_dataloader, optimizer, scheduler, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6BpPTrEBvEf",
        "outputId": "1fb4bca1-19e7-45c3-bef7-b69b572b558b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 27 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = outputs.max(1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Test Acc: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAUuBwOsB1wC"
      },
      "source": [
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   ResNet18  | 18 | 86% | 27% |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RlxgBzgwCV7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2c09c2-cc0f-4002-ce74-9bc243affc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 140MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "# Pre-trained resnet18 model\n",
        "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iTACUTgCYxf",
        "outputId": "543df91b-8a49-4900-bebe-87c45d6889d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 2.518 | Train Acc: 14.000%\n",
            "Epoch 1 Validation Acc: 17.315%\n",
            "Epoch 2 Train Loss: 2.097 | Train Acc: 27.500%\n",
            "Epoch 2 Validation Acc: 16.689%\n",
            "Epoch 3 Train Loss: 1.957 | Train Acc: 38.500%\n",
            "Epoch 3 Validation Acc: 20.529%\n",
            "Epoch 4 Train Loss: 1.640 | Train Acc: 45.000%\n",
            "Epoch 4 Validation Acc: 23.385%\n",
            "Epoch 5 Train Loss: 1.608 | Train Acc: 46.000%\n",
            "Epoch 5 Validation Acc: 21.996%\n",
            "Epoch 6 Train Loss: 1.432 | Train Acc: 48.000%\n",
            "Epoch 6 Validation Acc: 25.012%\n",
            "Epoch 7 Train Loss: 1.282 | Train Acc: 56.000%\n",
            "Epoch 7 Validation Acc: 26.036%\n",
            "Epoch 8 Train Loss: 1.161 | Train Acc: 59.000%\n",
            "Epoch 8 Validation Acc: 25.912%\n",
            "Epoch 9 Train Loss: 1.186 | Train Acc: 60.500%\n",
            "Epoch 9 Validation Acc: 27.124%\n",
            "Epoch 10 Train Loss: 0.804 | Train Acc: 73.000%\n",
            "Epoch 10 Validation Acc: 27.559%\n",
            "Epoch 11 Train Loss: 0.839 | Train Acc: 74.500%\n",
            "Epoch 11 Validation Acc: 26.373%\n",
            "Epoch 12 Train Loss: 0.803 | Train Acc: 72.000%\n",
            "Epoch 12 Validation Acc: 25.333%\n",
            "Epoch 13 Train Loss: 0.927 | Train Acc: 72.500%\n",
            "Epoch 13 Validation Acc: 25.679%\n",
            "Epoch 14 Train Loss: 0.989 | Train Acc: 67.500%\n",
            "Epoch 14 Validation Acc: 28.309%\n",
            "Epoch 15 Train Loss: 0.579 | Train Acc: 81.000%\n",
            "Epoch 15 Validation Acc: 28.000%\n",
            "Epoch 16 Train Loss: 0.690 | Train Acc: 79.000%\n",
            "Epoch 16 Validation Acc: 29.118%\n",
            "Epoch 17 Train Loss: 0.753 | Train Acc: 78.000%\n",
            "Epoch 17 Validation Acc: 27.557%\n",
            "Epoch 18 Train Loss: 0.681 | Train Acc: 79.500%\n",
            "Epoch 18 Validation Acc: 28.615%\n",
            "Epoch 19 Train Loss: 0.590 | Train Acc: 79.000%\n",
            "Epoch 19 Validation Acc: 29.361%\n",
            "Epoch 20 Train Loss: 0.488 | Train Acc: 85.500%\n",
            "Epoch 20 Validation Acc: 27.449%\n",
            "Epoch 21 Train Loss: 0.606 | Train Acc: 81.000%\n",
            "Epoch 21 Validation Acc: 28.469%\n",
            "Epoch 22 Train Loss: 0.524 | Train Acc: 83.500%\n",
            "Epoch 22 Validation Acc: 28.048%\n",
            "Epoch 23 Train Loss: 0.432 | Train Acc: 87.000%\n",
            "Epoch 23 Validation Acc: 29.080%\n",
            "Epoch 24 Train Loss: 0.427 | Train Acc: 86.000%\n",
            "Epoch 24 Validation Acc: 30.731%\n",
            "Epoch 25 Train Loss: 0.387 | Train Acc: 88.500%\n",
            "Epoch 25 Validation Acc: 28.477%\n",
            "Epoch 26 Train Loss: 0.332 | Train Acc: 91.500%\n",
            "Epoch 26 Validation Acc: 30.653%\n",
            "Epoch 27 Train Loss: 0.453 | Train Acc: 85.000%\n",
            "Epoch 27 Validation Acc: 30.407%\n",
            "Epoch 28 Train Loss: 0.370 | Train Acc: 88.500%\n",
            "Epoch 28 Validation Acc: 29.711%\n",
            "Epoch 29 Train Loss: 0.552 | Train Acc: 86.000%\n",
            "Epoch 29 Validation Acc: 28.914%\n",
            "Validation accuracy no longer improves for 5 epochs, early stopping.\n"
          ]
        }
      ],
      "source": [
        "best_model = train(model, 100, train_dataloader, unlabel_dataloader, optimizer, scheduler, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BCv7p71Gmwr",
        "outputId": "da00bca8-c4da-483c-bed2-05a9ead74891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 32 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_dataloader):\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = outputs.max(1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Test Acc: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "HRUA5I8N_2hk"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "RmyiWAPJ_2hl"
      },
      "source": [
        "__Question 7 (3 points) :__ Write a short report explaining the pros and the cons of each method that you implemented. 25% of the grade of this project will correspond to this question, thus, it should be done carefully. In particular, please add a plot that will summarize all your numerical results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "zJ-v4Nev_2hl"
      },
      "source": [
        "### Results\n",
        "\n",
        "<center>\n",
        "\n",
        "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
        "|------|------|------|------|\n",
        "|   ResNet18  | 18 | 100% | 24% |\n",
        "|   ResNet18 (pre-trained)  | 17 | 96% | 29% |\n",
        "|   ResNet18 (data augmentation)  | 18 | 86% | 27% |\n",
        "|   ResNet18 (pre-trained & data augmentation)  | 24 | 86% | 32% |\n",
        "\n",
        "\n",
        "<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "sAGp7ddN_2hl"
      },
      "source": [
        "# Weak supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "wHQRLbC3_2hl"
      },
      "source": [
        "__Bonus \\[open\\] question (up to 3 points) :__ Pick a weakly supervised method that will potentially use $\\mathcal{X}\\cup\\mathcal{X}_{\\text{train}}$ to train a representation (a subset of $\\mathcal{X}$ is also fine). Evaluate it and report the accuracies. You should be careful in the choice of your method, in order to avoid heavy computational effort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_ktag": "wDy8ur1Ynu58",
        "id": "rbjhfIvN_2hl"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "kfiletag": "wDy8ur1Ynu58",
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}